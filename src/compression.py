"""
Top-K gradient sparsification for communication-efficient FL.

Only the K% largest (by magnitude) gradient values are transmitted,
with the rest set to zero. This reduces communication overhead by
40-60% with negligible accuracy loss.

Includes optional error feedback mechanism (residual accumulation).
"""

import logging
import numpy as np
from typing import Dict, List, Optional, Tuple

logger = logging.getLogger("ppfl-ncd.compression")


def topk_compress(
    gradients: List[np.ndarray],
    k_ratio: float = 0.1,
) -> Tuple[List[np.ndarray], Dict[str, float]]:
    """
    Apply Top-K sparsification to gradient arrays.
    
    Keeps only the top k_ratio fraction of gradient values (by magnitude),
    setting the rest to zero.
    
    Args:
        gradients: List of gradient arrays (one per model parameter)
        k_ratio: Fraction of gradient values to keep (0.1 = top 10%)
    
    Returns:
        (compressed_gradients, stats_dict)
    """
    # Flatten all gradients to find global threshold
    flat = np.concatenate([g.flatten() for g in gradients])
    total_params = len(flat)
    k = max(1, int(total_params * k_ratio))
    
    # Find the k-th largest magnitude
    abs_flat = np.abs(flat)
    # Use partition for O(n) instead of full sort O(n log n)
    if k < total_params:
        threshold_idx = total_params - k
        partition = np.partition(abs_flat, threshold_idx)
        threshold = partition[threshold_idx]
    else:
        threshold = 0.0
    
    # Apply mask to each gradient array
    compressed = []
    nonzero_count = 0
    for g in gradients:
        mask = np.abs(g) >= threshold
        comp = g * mask
        compressed.append(comp)
        nonzero_count += mask.sum()
    
    # Compute stats
    original_bytes = total_params * 4  # float32
    compressed_bytes = nonzero_count * (4 + 4)  # value + index in sparse format
    
    stats = {
        "total_params": total_params,
        "nonzero_params": int(nonzero_count),
        "k_ratio": k_ratio,
        "actual_ratio": float(nonzero_count / total_params),
        "threshold": float(threshold),
        "original_bytes": original_bytes,
        "compressed_bytes": int(compressed_bytes),
        "compression_ratio": float(compressed_bytes / max(original_bytes, 1)),
        "savings_pct": float(1.0 - compressed_bytes / max(original_bytes, 1)) * 100,
    }
    
    return compressed, stats


class ErrorFeedbackCompressor:
    """
    Top-K compression with error feedback (residual accumulation).
    
    Unselected gradient values are accumulated and added to the next
    round's gradients, ensuring no information is permanently lost.
    This significantly improves convergence under heavy compression.
    """
    
    def __init__(self, k_ratio: float = 0.1):
        self.k_ratio = k_ratio
        self.residuals: Optional[List[np.ndarray]] = None
    
    def compress(
        self, gradients: List[np.ndarray]
    ) -> Tuple[List[np.ndarray], Dict[str, float]]:
        """
        Compress gradients with error feedback.
        
        Args:
            gradients: List of gradient arrays
        
        Returns:
            (compressed_gradients, stats)
        """
        # Add accumulated residuals from previous rounds
        if self.residuals is not None:
            gradients = [
                g + r for g, r in zip(gradients, self.residuals)
            ]
        
        # Apply Top-K compression
        compressed, stats = topk_compress(gradients, self.k_ratio)
        
        # Store residuals (what was dropped)
        self.residuals = [g - c for g, c in zip(gradients, compressed)]
        
        return compressed, stats
    
    def reset(self):
        """Reset accumulated residuals."""
        self.residuals = None


def estimate_communication_cost(
    model_params: int,
    num_clients: int,
    num_rounds: int,
    k_ratio: float = 0.1,
) -> Dict[str, float]:
    """
    Estimate total communication cost for an FL experiment.
    
    Args:
        model_params: Total number of model parameters
        num_clients: Number of FL clients
        num_rounds: Number of FL rounds
        k_ratio: Compression ratio
    
    Returns:
        Dict with communication cost estimates
    """
    bytes_per_param = 4  # float32
    
    # Uncompressed: each client sends full model update each round
    uncompressed_per_round = model_params * bytes_per_param * num_clients * 2  # up + down
    uncompressed_total = uncompressed_per_round * num_rounds
    
    # Compressed: only k_ratio fraction sent (+ indices)
    compressed_params = int(model_params * k_ratio)
    compressed_per_round = compressed_params * (bytes_per_param + 4) * num_clients * 2
    compressed_total = compressed_per_round * num_rounds
    
    return {
        "model_params": model_params,
        "uncompressed_total_mb": uncompressed_total / (1024 ** 2),
        "compressed_total_mb": compressed_total / (1024 ** 2),
        "savings_mb": (uncompressed_total - compressed_total) / (1024 ** 2),
        "savings_pct": (1 - compressed_total / max(uncompressed_total, 1)) * 100,
        "k_ratio": k_ratio,
    }


def run_compression_sweep(
    gradients: List[np.ndarray],
    k_ratios: List[float] = None,
) -> List[Dict]:
    """
    Run compression experiments with different k_ratios.
    
    Args:
        gradients: Sample gradient arrays
        k_ratios: List of compression ratios to test
    
    Returns:
        List of stats dicts, one per k_ratio
    """
    if k_ratios is None:
        k_ratios = [0.05, 0.1, 0.2, 0.5, 1.0]
    
    results = []
    for kr in k_ratios:
        compressed, stats = topk_compress(gradients, kr)
        
        # Measure reconstruction error
        original_flat = np.concatenate([g.flatten() for g in gradients])
        compressed_flat = np.concatenate([c.flatten() for c in compressed])
        mse = float(np.mean((original_flat - compressed_flat) ** 2))
        
        stats["reconstruction_mse"] = mse
        results.append(stats)
        
        logger.info(
            f"  k_ratio={kr:.2f} â†’ "
            f"savings={stats['savings_pct']:.1f}%, "
            f"MSE={mse:.6f}"
        )
    
    return results
